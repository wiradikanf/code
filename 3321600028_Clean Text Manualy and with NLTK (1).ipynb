{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd9711fe",
   "metadata": {},
   "source": [
    "## Manual Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda0dc77",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fileLatihan.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21412/1443518170.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#load text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'fileLatihan.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fileLatihan.txt'"
     ]
    }
   ],
   "source": [
    "#Load Data \n",
    "#load text\n",
    "filename = 'fileLatihan.txt' \n",
    "file = open(filename, 'r') \n",
    "text = file.read() \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781dceab",
   "metadata": {},
   "source": [
    "## Split by Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ff4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "filename = 'fiIeLatihan.txt'\n",
    "file = open(filename, 'rt') \n",
    "text = file.read() \n",
    "file.close()\n",
    "# split into words by white space \n",
    "words = text.split() \n",
    "print(words[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4991d705",
   "metadata": {},
   "source": [
    "## Select Words with regex model (re)\n",
    "split the document into words by\n",
    "selecting for strings of alphanumeric characters (a-z, A-Z, 0-9 and\tâ€™)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35063f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "filename = 'fiIeLatihan.txt'\n",
    "file = open(filename, 'rt') \n",
    "text = file.read() \n",
    "file.close()\n",
    "# split based on words only\n",
    "words = re.split(r'\\W+', text) \n",
    "print(words[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362170aa",
   "metadata": {},
   "source": [
    "## Split by Whitespace and Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef334fe",
   "metadata": {},
   "source": [
    "## Use regular expressions to select for the punctuation characters and use the sub() function to replace them with nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced99d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_punc = re.compile('[%s]'%re.escape(string.punctuation))\n",
    "#romove punctuation from 1each word\n",
    "stripped = [re_punc.sub(\" \",w) for w in windows] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e6bbc",
   "metadata": {},
   "source": [
    "## Manually remove punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eaa14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "filename = 'fiIeLatihan.txt' \n",
    "file = open(filename, 'rt')\n",
    "text = file.read() \n",
    "file.close()\n",
    "# split into words by white space words = text.split()\n",
    "# prepare regex for char filtering\n",
    "re_punc = re.compile('[%s]'%re.escape(string.punctuation)) # remove punctuation from each word\n",
    "stripped = [re_punc.sub(\"\", w) for w in words] \n",
    "print(stripped[:100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b862b4",
   "metadata": {},
   "source": [
    "## Example of removing non-printable characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1daf10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.print = re.compile('[^%s]' % re.escape(string.printable)) \n",
    "result = [re.print.sub(\"\", w) for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8111ade",
   "metadata": {},
   "source": [
    "## lower() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "filename = 'fileLatihan.txt' \n",
    "file = open(filename, 'rt') \n",
    "text = file.read() \n",
    "file.close()\n",
    "# split into words by white space\n",
    "words = text.split()\n",
    "words = [word.lower() for word in words]\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464e53f5",
   "metadata": {},
   "source": [
    "## Install NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88701d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -u nltk\n",
    "\n",
    "# setelah berhasil dilanjutkan\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6542d5c",
   "metadata": {},
   "source": [
    "## Split into Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0175d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent tokenize\n",
    "# load data\n",
    "filename = 'fileLatihan.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into sentences\n",
    "sentences = sent tokenize(text)\n",
    "print(sentences[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca2876",
   "metadata": {},
   "source": [
    "## Split into Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd0723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word\ttokenize\n",
    "# load data\n",
    "filename = 'fileLatihan.txt' \n",
    "file = open(filename, 'rt') \n",
    "text = file.read() \n",
    "file.close()\n",
    "# split into words\n",
    "tokens = word tokenize(text)\n",
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f8b07",
   "metadata": {},
   "source": [
    "## Filter Out Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word tokenize\n",
    "# load data\n",
    "filename = 'fileLatihan.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words\n",
    "tokens = word tokenize(text)\n",
    "# remove all tokens that are not alphabetic\n",
    "words = [word for word in tokens if word.isalpha()]\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15189a11",
   "metadata": {},
   "source": [
    "## Stop Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0320ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop words = stopwords.words('english') \n",
    "print(stop words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bf90b1",
   "metadata": {},
   "source": [
    "## NLTK sederhana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e83a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string import re\n",
    "from nltk.tokenize import word tokenize \n",
    "from nltk.corpus import stopwords\n",
    "# load data\n",
    "filename = 'fileLatihan.txt' \n",
    "file = open(filename, 'rt') \n",
    "text = file.read() \n",
    "file.close()\n",
    "# split into words\n",
    "tokens = word tokenize(text) # convert to lower case\n",
    "tokens = [w.lower() for w in tokens] # prepare regex for char filtering\n",
    "re punc = re.compile('[%s]' % re.escape(string.punctuation)) # remove punctuation from each word\n",
    "stripped = [re punc.sub(\"\", w) for w in tokens]\n",
    "# remove remaining tokens that are not alphabetic words = [word for word in stripped if word.isaIpha()] # filter out stop words\n",
    "stop words = set(stopwords.words('english')) \n",
    "words = [w for w in words if not w in stop words] \n",
    "print(words[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d82b9c",
   "metadata": {},
   "source": [
    "## Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word tokenize \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "# load data\n",
    "filename = 'fileLatihan.txt' \n",
    "file = open(filename, 'rt') \n",
    "text = file.read() \n",
    "file.close()\n",
    "# split into words\n",
    "tokens = word tokenize(text)\n",
    "# stemming of words\n",
    "porter = PorterStemmer()\n",
    "stemmed = [porter.stem(word) for word in tokens]\n",
    "print(stemmed[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
